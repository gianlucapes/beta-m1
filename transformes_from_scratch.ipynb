{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf55d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # DEFINIZIONE: Non chiamare .cuda() qui. Lascia i layer neutri.\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, embed_dim)\n",
    "        \n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "        \n",
    "        # Moltiplicazione matriciale: Q @ K^T\n",
    "        scores = Q @ K.transpose(-2, -1)\n",
    "        \n",
    "        # Scaling\n",
    "        scores = scores / (self.embed_dim ** 0.5)\n",
    "        \n",
    "        # Softmax\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # Output finale\n",
    "        output = attn_weights @ V\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db9acfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sto usando il device: cuda\n",
      "Input shape: torch.Size([2, 10, 64])\n",
      "Output shape: torch.Size([2, 10, 64])\n",
      "Output device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 1. Definisci il device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Sto usando il device: {device}\")\n",
    "\n",
    "# 2. Crea il layer\n",
    "attention = SelfAttention(embed_dim=64)\n",
    "\n",
    "# 3. Sposta il MODELLO sul device (GPU)\n",
    "attention.to(device)\n",
    "\n",
    "# 4. Crea l'input\n",
    "x = torch.randn(2, 10, 64)\n",
    "\n",
    "# --- CORREZIONE QUI SOTTO ---\n",
    "# 5. Devi spostare anche i DATI sul device (GPU)\n",
    "x = x.to(device) \n",
    "# ----------------------------\n",
    "\n",
    "# 6. Ora puoi applicare l'attenzione\n",
    "# (Entrambi, modello e x, sono ora sullo stesso device)\n",
    "output = attention(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")      \n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output device: {output.device}\") # Verifica che l'output sia su cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547391c",
   "metadata": {},
   "source": [
    "### Working Through a Manual Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab58992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Input: 3 word embeddings, 4 dimensions each\n",
    "x = torch.tensor([[1.0, 0.0, 1.0, 0.0],  # Word 1: \"The\"\n",
    "                  [0.0, 1.0, 0.0, 1.0],  # Word 2: \"cat\"\n",
    "                  [1.0, 1.0, 0.0, 0.0]]) # Word 3: \"sat\"\n",
    "x=x.to(device)\n",
    "print(f\"Input shape: {x.shape}\")  # torch.Size([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a594e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random weight matrices\n",
    "# In practice, these are learned during training\n",
    "W_q = torch.randn(4, 4).to(device)  # Query projection\n",
    "W_k = torch.randn(4, 4).to(device)  # Key projection\n",
    "W_v = torch.randn(4, 4).to(device)  # Value projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce13b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q shape: torch.Size([3, 4])\n",
      "K shape: torch.Size([3, 4])\n",
      "V shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Transform input into Q, K, V\n",
    "# Notice: all three come from the SAME input x!\n",
    "Q = x @ W_q  # Shape: (3, 4)\n",
    "K = x @ W_k  # Shape: (3, 4)\n",
    "V = x @ W_v  # Shape: (3, 4)\n",
    "\n",
    "print(f\"Q shape: {Q.shape}\")  # torch.Size([3, 4])\n",
    "print(f\"K shape: {K.shape}\")  # torch.Size([3, 4])\n",
    "print(f\"V shape: {V.shape}\")  # torch.Size([3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c676937d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores shape: torch.Size([3, 3])\n",
      "Scores:\n",
      "tensor([[-2.5850,  0.3489, -2.3574],\n",
      "        [ 1.1196, -0.1771,  1.1724],\n",
      "        [-0.8364, -0.5975, -0.4580]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Similarity between all query-key pairs\n",
    "d_k = 4\n",
    "scores = Q @ K.T / (d_k ** 0.5)\n",
    "\n",
    "print(f\"Scores shape: {scores.shape}\")  # torch.Size([3, 3])\n",
    "print(\"Scores:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7842844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights:\n",
      "tensor([[0.0475, 0.8929, 0.0596],\n",
      "        [0.4296, 0.1175, 0.4529],\n",
      "        [0.2681, 0.3405, 0.3914]], device='cuda:0')\n",
      "\\nRow 0 sum: 0.9999999403953552\n"
     ]
    }
   ],
   "source": [
    "attn_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "print(\"Attention weights:\")\n",
    "print(attn_weights)\n",
    "print(f\"\\\\nRow 0 sum: {attn_weights[0].sum()}\")  # 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c62decb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nOutput shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Weighted combination of all value vectors\n",
    "output = attn_weights @ V\n",
    "\n",
    "print(f\"\\\\nOutput shape: {output.shape}\")  # torch.Size([3, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
