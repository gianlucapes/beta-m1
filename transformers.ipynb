{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f98cf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xamon/Documenti/ricerca_formazione/custom_neural_networks/.venv/lib/python3.13/site-packages/torch/_subclasses/functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095b2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "embeddings = model.encode(['Ciao mondo', 'Hello world'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf173c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Disponibile: True\n"
     ]
    }
   ],
   "source": [
    "# Il momento della verit√†\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(f\"GPU Disponibile: {is_cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63de5f3",
   "metadata": {},
   "source": [
    "### Weighted Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44fab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input sequence (3 words, each 4-dim embedding)\n",
    "sequence = torch.tensor([[0.1, 0.2, 0.3, 0.4],  # word 1: \"The\"\n",
    "                         [0.5, 0.6, 0.7, 0.8],  # word 2: \"cat\"\n",
    "                         [0.9, 1.0, 1.1, 1.2]]).cuda() # word 3: \"sat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52576a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = torch.tensor([0.1, 0.3, 0.6]).cuda()  # Weights for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0487b972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7000, 0.8000, 0.9000, 1.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Weighted average\n",
    "output = torch.zeros(4).cuda()\n",
    "for i, weight in enumerate(attention_weights):\n",
    "    output += weight * sequence[i]\n",
    "\n",
    "print(output)\n",
    "# tensor([0.7000, 0.8000, 0.9000, 1.0000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84297bea",
   "metadata": {},
   "source": [
    "$$(\\text{W}_1 \\cdot \\text{Seq}_1) + (\\text{W}_2 \\cdot \\text{Seq}_2) + (\\text{W}_3 \\cdot \\text{Seq}_3)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722d462",
   "metadata": {},
   "source": [
    "### Concrete Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b44dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: \"Looking for subject-related information\"\n",
    "query = torch.tensor([1.0, 0.0, 1.0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "284215c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys: what each position represents\n",
    "keys = torch.tensor([[1.0, 0.0, 1.0],  # Position 0: matches query well!\n",
    "                     [0.0, 1.0, 0.0],  # Position 1: completely different\n",
    "                     [1.0, 0.0, 0.8]]).cuda() # Position 2: somewhat similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58d11187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values: actual information at each position\n",
    "values = torch.tensor([[10.0, 20.0],  # Info at position 0\n",
    "                       [30.0, 40.0],  # Info at position 1\n",
    "                       [50.0, 60.0]]).cuda()  # Info at position 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2530f120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: tensor([2.0000, 0.0000, 1.8000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Dot product measures similarity\n",
    "scores = keys @ query\n",
    "print(\"Scores:\", scores)\n",
    "# tensor([2.0000, 0.0000, 1.8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd52402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: tensor([0.5118, 0.0693, 0.4190], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "weights = F.softmax(scores, dim=0)\n",
    "print(\"Weights:\", weights)\n",
    "# tensor([0.5308, 0.0874, 0.3818])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "340dc246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([28.1447, 38.1447], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Combine values using attention weights\n",
    "output = torch.zeros(2).cuda()\n",
    "for i, weight in enumerate(weights):\n",
    "    output += weight * values[i]\n",
    "\n",
    "print(\"Output:\", output)\n",
    "# tensor([28.1820, 38.1820])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f518ac88",
   "metadata": {},
   "source": [
    "### Build a simple attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e450e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        # Three learned linear transformations\n",
    "        self.query = nn.Linear(embed_dim, embed_dim).cuda()\n",
    "        self.key = nn.Linear(embed_dim, embed_dim).cuda()\n",
    "        self.value = nn.Linear(embed_dim, embed_dim).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, embed_dim)\n",
    "        # Example: (1, 10, 64) = 1 sentence, 10 words, 64-dim embeddings\n",
    "        # Transform input into Query, Key, Value\n",
    "        Q = self.query(x)  # What each position is looking for\n",
    "        K = self.key(x)    # What each position represents\n",
    "        V = self.value(x)  # What info each position has\n",
    "        # Calculate similarity between queries and keys\n",
    "        scores = Q @ K.transpose(-2, -1)\n",
    "        # Shape: (batch, seq_len, seq_len)\n",
    "        # scores[i,j] = how much position i attends to position j\n",
    "        # Scale by square root of dimension\n",
    "        d_k = Q.size(-1)\n",
    "        scores = scores / (d_k ** 0.5)\n",
    "        # Softmax gives probability distribution\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        # Each row sums to 1!\n",
    "        # Weighted combination of values\n",
    "        output = attn_weights @ V\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49af1f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 10, 64])\n",
      "Output shape: torch.Size([1, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# Create attention layer\n",
    "attention = SimpleAttention(embed_dim=64)\n",
    "\n",
    "# Input: 1 batch, 10 words, 64-dim embeddings\n",
    "x = torch.randn(1, 10, 64).cuda()\n",
    "\n",
    "# Apply attention\n",
    "output = attention(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")      # torch.Size([1, 10, 64])\n",
    "print(f\"Output shape: {output.shape}\") # torch.Size([1, 10, 64])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom_neural_networks (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
